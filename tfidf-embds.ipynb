{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y3XX0p7IQkrf"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_zXKohni5LtO"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q4epZNhk47Hv"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import sqlite3\n",
        "import matplotlib.pyplot as plt\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "pd.set_option('display.max_rows', 500)\n",
        "import seaborn as sns\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7DpsdQVAQtCz"
      },
      "outputs": [],
      "source": [
        "cnx = sqlite3.connect('/content/gdrive/MyDrive/data.db')\n",
        "df = pd.read_sql_query('SELECT * FROM Article', cnx)\n",
        "in_category = pd.read_sql_query('SELECT * FROM in_category', cnx)\n",
        "df['Date'] = pd.to_datetime(df['Date'], utc=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ExvGIZBeclj4"
      },
      "outputs": [],
      "source": [
        "df_test = pd.read_sql_query(\"\"\"SELECT * from Article \n",
        "INNER JOIN In_category ON In_category.articleID = Article.articleID \n",
        "INNER JOIN Category ON Category.categoryID = In_category.categoryID\"\"\", cnx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uffGCC-sdemX"
      },
      "outputs": [],
      "source": [
        "df_categories = pd.read_sql_query('SELECT * from In_category', cnx)\n",
        "df_categories.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-U648TY3Q8Ms"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "df['Content'] = df.Title + \" \" + df.Description\n",
        "df['Content'] = df['Content'].str.lower()\n",
        "df['Content'] = df['Content'].str.replace('[^\\w\\s]', ' ')\n",
        "\n",
        "with open('/content/gdrive/MyDrive/stopwords-hr.txt', 'r') as f:\n",
        "  stopwords = [x.strip() for x in f.readlines()]\n",
        "\n",
        "replace = re.compile(r'\\b(' + ('|'.join(stopwords)) + r')\\b')\n",
        "\n",
        "df['Content'] = df['Content'].str.replace(replace, '')\n",
        "df['Content'] = df['Content'].str.replace(re.compile('\\s{2,}'), ' ')\n",
        "df['Content'] = df['Content'].astype(str)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ME48HUhQRENm"
      },
      "outputs": [],
      "source": [
        "sample = df.sample(1)\n",
        "sample_idx = sample.index.item()\n",
        "sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M8ruvFRABXae"
      },
      "outputs": [],
      "source": [
        "print(sample['Content'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_nTv0n34Csvu"
      },
      "outputs": [],
      "source": [
        "#print((df[\"Description\"] <= \"\\n\").value_counts())\n",
        "df['Description'].str.count('\\s+').lt(5).value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CknY_uTPKNN9"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "def preprocess(text):\n",
        "  return nltk.word_tokenize(text)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q6xGTxsWI9d7"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "f = open('/content/gdrive/MyDrive/stopwords-hr.txt')\n",
        "stop_words = f.read().splitlines() \n",
        "f.close()\n",
        "vectorizer = TfidfVectorizer(tokenizer=preprocess, stop_words=stop_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FfLysjZkKhtf"
      },
      "outputs": [],
      "source": [
        "def compute_similarity(a, b):\n",
        "  tfidf = vectorizer.fit_transform([a, b])\n",
        "  return ((tfidf * tfidf.T).toarray())[0,1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bKMbT2C3QMOd"
      },
      "outputs": [],
      "source": [
        "def wrapper_compute_similarity(a, b):\n",
        "  return compute_similarity(str(a['Content']), str(b['Content']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-n9oCoJRMcJm"
      },
      "outputs": [],
      "source": [
        "df_subset = df.sample(10000)\n",
        "specific_row = df.loc[sample_idx]\n",
        "result = df_subset.apply(wrapper_compute_similarity, args=(specific_row,), axis=1)\n",
        "#compute_similarity(str(a[\"Content\"]), str(b[\"Content\"]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bCXxcrkXUmDW"
      },
      "outputs": [],
      "source": [
        "result.sort_values(ascending=False, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CyViwcFEVoO4"
      },
      "outputs": [],
      "source": [
        "sample[\"Content\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xfJdugSRffgQ"
      },
      "outputs": [],
      "source": [
        "df_best = result[:5]\n",
        "df_selected = df.iloc[df_best.index]\n",
        "df_selected[\"Similarity\"] = result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JfJoxWMGgHrB"
      },
      "outputs": [],
      "source": [
        "df_best"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mlHcIPPOgBdw"
      },
      "outputs": [],
      "source": [
        "df_selected"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XLDzc0zemGUy"
      },
      "outputs": [],
      "source": [
        "X = vectorizer.fit_transform(df_subset['Content'])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import silhouette_score, davies_bouldin_score\n",
        "from sklearn.cluster import KMeans\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def generate_metrics(X, max_clusters):\n",
        "  range_n_clusters = range(2, max_clusters)\n",
        "  silhouette_scores = list()\n",
        "  davis_bouldin_scores = list()\n",
        "  labels_per_cluster_num = dict()\n",
        "  for n_clusters in range_n_clusters:\n",
        "      kmeans = KMeans(n_clusters=n_clusters)\n",
        "      kmeans.fit(X)\n",
        "      results = kmeans.predict(X)\n",
        "      silhouette_scores.append(silhouette_score(X, kmeans.labels_))\n",
        "      davis_bouldin_scores.append(davies_bouldin_score(X.toarray(), kmeans.labels_))\n",
        "      labels_per_cluster_num[n_clusters] = kmeans.labels_\n",
        "  \n",
        "  plt.plot(range_n_clusters, silhouette_scores, '-o', label='Silhouette score')\n",
        "  plt.xlabel(\"Number of clusters\")\n",
        "  plt.ylabel(\"Silhouette score\")\n",
        "  plt.title(\"TF-IDF\")\n",
        "  plt.savefig('silhouette.png', bbox_inches='tight')\n",
        "  plt.show()\n",
        "  plt.plot(range_n_clusters, davis_bouldin_scores, '-o', label='Davies-Bouldin score')\n",
        "  plt.xlabel(\"Number of clusters\")\n",
        "  plt.ylabel(\"Davies-Bouldin score\")\n",
        "  plt.title(\"TF-IDF\")\n",
        "  plt.savefig('davies_bouldin.png', bbox_inches='tight')\n",
        "  plt.show()\n",
        "\n",
        "  return labels_per_cluster_num\n"
      ],
      "metadata": {
        "id": "6M01c8hEREyk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6inSSEH_KnJz"
      },
      "outputs": [],
      "source": [
        "!pip -q install umap-learn\n",
        "from sklearn.decomposition import PCA\n",
        "from bokeh.plotting import figure, show\n",
        "from bokeh.palettes import Category20_20 as palette\n",
        "from bokeh.io import output_notebook\n",
        "import itertools\n",
        "import umap\n",
        "from sklearn.manifold import TSNE\n",
        "\n",
        "def generate_visuals(X, labels_per_cluster_num, chosen_cluster_num):\n",
        "  # Call once to configure Bokeh to display plots inline in the notebook.\n",
        "  output_notebook()\n",
        "  df_subset['cluster'] = labels_per_cluster_num[chosen_cluster_num]\n",
        "\n",
        "  #PCA\n",
        "  pca = PCA(n_components=2, random_state=42)\n",
        "  pca_vecs = pca.fit_transform(X.toarray())\n",
        "\n",
        "  x0 = pca_vecs[:, 0]\n",
        "  x1 = pca_vecs[:, 1]\n",
        "\n",
        "  df_subset['x0_pca'] = x0\n",
        "  df_subset['x1_pca'] = x1\n",
        "\n",
        "  colors = itertools.cycle(palette)\n",
        "  p = figure(plot_width=600, plot_height=450, title = \"PCA\", tooltips=\"@Title\")\n",
        "  for i in range(chosen_cluster_num):\n",
        "    p.scatter('x0_pca', 'x1_pca', source=df_subset[df_subset['cluster'] == i], color = next(colors))\n",
        "  show(p)\n",
        "\n",
        "  #TSNE\n",
        "  tsne = TSNE(n_components=2, learning_rate='auto', init='random', perplexity=30)\n",
        "  tsne_vecs = tsne.fit_transform(X.toarray())\n",
        "\n",
        "  x0 = tsne_vecs[:, 0]\n",
        "  x1 = tsne_vecs[:, 1]\n",
        "\n",
        "  df_subset['x0_tsne'] = x0\n",
        "  df_subset['x1_tsne'] = x1\n",
        "\n",
        "  colors = itertools.cycle(palette)\n",
        "  p = figure(plot_width=600, plot_height=450, title = \"TSNE\", tooltips=\"@Title\")\n",
        "  for i in range(chosen_cluster_num):\n",
        "    p.scatter('x0_tsne', 'x1_tsne', source=df_subset[df_subset['cluster'] == i], color = next(colors))\n",
        "  show(p)\n",
        "\n",
        "  #UMAP\n",
        "  reducer = umap.UMAP()\n",
        "  umap_vecs = reducer.fit_transform(X.toarray())\n",
        "\n",
        "  x0 = umap_vecs[:, 0]\n",
        "  x1 = umap_vecs[:, 1]\n",
        "\n",
        "  df_subset['x0_umap'] = x0\n",
        "  df_subset['x1_umap'] = x1\n",
        "\n",
        "  colors = itertools.cycle(palette)\n",
        "  p = figure(plot_width=600, plot_height=450, title = \"UMAP\", tooltips=\"@Title\")\n",
        "  for i in range(chosen_cluster_num):\n",
        "    p.scatter('x0_umap', 'x1_umap', source=df_subset[df_subset['cluster'] == i], color = next(colors))\n",
        "  show(p)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels_per_cluster_num = generate_metrics(X, 20)"
      ],
      "metadata": {
        "id": "fD4E0YarUr9C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generate_visuals(X, labels_per_cluster_num, 16)"
      ],
      "metadata": {
        "id": "QjSegMd5UxyY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generate_visuals(X, labels_per_cluster_num, 8)"
      ],
      "metadata": {
        "id": "2GFIelNXgTRR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U sentence-transformers\n",
        "from sentence_transformers import util\n",
        "\n",
        "def get_example_neighs(example_idx,embds):\n",
        "    cos_sim = util.cos_sim(embds,embds)\n",
        "    example_neighs = cos_sim.numpy()[example_idx]\n",
        "    indices = np.argsort(example_neighs)[-6:-1]\n",
        "    indices = list(indices)[::-1]\n",
        "    indices.insert(0,example_idx)\n",
        "    \n",
        "    out_df = pd.DataFrame()\n",
        "    out_df[\"Article\"] = [df_subset.iloc[idx]['Content'] for idx in indices]\n",
        "    out_df[\"Cosine Similarity\"] = example_neighs[indices]\n",
        "    \n",
        "    return out_df"
      ],
      "metadata": {
        "id": "QkcqAQAHOEz8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_subset.iloc[103]['Content']"
      ],
      "metadata": {
        "id": "7eeE6soLUTEc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_example_neighs(103,X.toarray())"
      ],
      "metadata": {
        "id": "VEIacmDsOYD9"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}